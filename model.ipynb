{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from data.load_data import get_plant_leaves_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = get_plant_leaves_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 256, 256, 3)\n",
      "(450, 256, 256, 3)\n",
      "(451, 256, 256, 3)\n",
      "(3601, 2)\n",
      "(450, 2)\n",
      "(451, 2)\n"
     ]
    }
   ],
   "source": [
    "# Image Data Shape\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)\n",
    "# Label Data Shape\n",
    "print(y_train.shape)\n",
    "print(y_validation.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "The model is of a ResNet architecture, with convolution layers and the input from each layer being added to the end of it. Rather than fully connected layers, Global Average Pooling is used. The model is then trained on 100 epochs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Dropout, ReLU, Softmax\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Dropout, ReLU, Softmax\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ResNet Model\n",
    "def create_model(input, classes, l2_reg = 0.005):\n",
    "   reg = l2(l2_reg)\n",
    "\n",
    "   # Model\n",
    "   img_input = Input(input)\n",
    "   model = Conv2D(4, kernel_size = (3, 3), strides = (1, 1), kernel_regularizer = reg, use_bias = False)(img_input)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = ReLU()(model)\n",
    "   model = Conv2D(4, kernel_size = (3, 3), strides = (1, 1), kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = ReLU()(model)\n",
    "\n",
    "   res = Conv2D(8, kernel_size = (1, 1), strides = (2, 2), kernel_regularizer = reg, use_bias = False)(model)\n",
    "   res = BatchNormalization()(res)\n",
    "\n",
    "   model = Conv2D(8, kernel_size = (3, 3), padding = 'same', kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = ReLU()(model)\n",
    "   model = Conv2D(8, kernel_size = (3, 3), padding = 'same', kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = MaxPooling2D(pool_size = (3, 3), strides = (2, 2), padding = 'same')(model)\n",
    "   model = layers.add([model, res])\n",
    "\n",
    "   res = Conv2D(16, kernel_size = (1, 1), strides = (2, 2), padding = 'same', use_bias = False)(model)\n",
    "   res = BatchNormalization()(res)\n",
    "\n",
    "   model = Conv2D(16, kernel_size = (3, 3), padding = 'same', kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = ReLU()(model)\n",
    "   model = Conv2D(16, kernel_size = (3, 3), padding = 'same', kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = MaxPooling2D(pool_size = (3, 3), strides = (2, 2), padding = 'same')(model)\n",
    "   model = layers.add([model, res])\n",
    "\n",
    "   res = Conv2D(32, kernel_size = (1, 1), strides = (2, 2), padding = 'same', use_bias = False)(model)\n",
    "   res = BatchNormalization()(res)\n",
    "\n",
    "   model = Conv2D(32, kernel_size = (3, 3), padding = 'same', kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = ReLU()(model)\n",
    "   model = Conv2D(32, kernel_size = (3, 3), padding = 'same', kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = MaxPooling2D(pool_size = (3, 3), strides = (2, 2), padding = 'same')(model)\n",
    "   model = layers.add([model, res])\n",
    "\n",
    "   res = Conv2D(64, kernel_size = (1, 1), strides = (2, 2), padding = 'same', use_bias = False)(model)\n",
    "   res = BatchNormalization()(res)\n",
    "\n",
    "   model = Conv2D(64, kernel_size = (3, 3), padding = 'same', kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = ReLU()(model)\n",
    "   model = Conv2D(64, kernel_size = (3, 3), padding = 'same', kernel_regularizer = reg, use_bias = False)(model)\n",
    "   model = BatchNormalization()(model)\n",
    "   model = MaxPooling2D(pool_size = (3, 3), strides = (2, 2), padding = 'same')(model)\n",
    "   model = layers.add([model, res])\n",
    "\n",
    "   model = Conv2D(classes, kernel_size = (3, 3), padding = 'same')(model)\n",
    "   model = GlobalAvgPool2D()(model)\n",
    "\n",
    "   output = Softmax(name = 'predictions')(model)\n",
    "\n",
    "   model = Model(img_input, output)\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model((256, 256, 3), 2)\n",
    "model.compile(\n",
    "   optimizer = Adam(),\n",
    "   loss = categorical_crossentropy,\n",
    "   metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 254, 254, 4)  108         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 254, 254, 4)  16          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 254, 254, 4)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 252, 252, 4)  144         re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 252, 252, 4)  16          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 252, 252, 4)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 252, 252, 8)  288         re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 252, 252, 8)  32          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 252, 252, 8)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 252, 252, 8)  576         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 252, 252, 8)  32          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 126, 126, 8)  32          re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 126, 126, 8)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 126, 126, 8)  32          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 126, 126, 8)  0           max_pooling2d_4[0][0]            \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 126, 126, 16) 1152        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 126, 126, 16) 64          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 126, 126, 16) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 126, 126, 16) 2304        re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 126, 126, 16) 64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 63, 63, 16)   128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 63, 63, 16)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 63, 63, 16)   64          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 63, 63, 16)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 63, 63, 32)   4608        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 63, 63, 32)   128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 63, 63, 32)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 63, 63, 32)   9216        re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 63, 63, 32)   128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 32)   512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 32)   128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 32)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 64)   18432       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 32, 32, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 64)   36864       re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 64)   2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 64)   0           max_pooling2d_7[0][0]            \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 2)    1154        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2)            0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Softmax)           (None, 2)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 79,038\n",
      "Trainable params: 78,302\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "\n",
    "train_flow = datagen.flow(X_train, y_train, 32)\n",
    "validation_flow = datagen.flow(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "datadir = os.path.join(os.getcwd(), \"data\", \"model\")\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 50)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = int(50 / 4), verbose = 1)\n",
    "save_path = os.path.join(datadir, \"model\", \"Model-{epoch:02d}-{val_accuracy:.4f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(save_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "callbacks = [checkpoint, reduce_lr, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "   train_flow,\n",
    "   epochs = 100,\n",
    "   verbose = 1,\n",
    "   callbacks = callbacks,\n",
    "   validation_data = validation_flow\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}